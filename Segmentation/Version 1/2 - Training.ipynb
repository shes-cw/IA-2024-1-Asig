{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the UNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"midterm\"] = str(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 256\n",
    "width = 256\n",
    "\n",
    "batch_size = 32\n",
    "lr = 2e-4\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset\"\n",
    "\n",
    "files_dir = \"files\"\n",
    "model_file = os.path.join(files_dir, \"unet.h5\")\n",
    "log_file = os.path.join(files_dir, \"log.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir(files_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building UNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_attention_module(x, ratio=8):\n",
    "    channel = x.shape[-1]\n",
    "    \n",
    "    l1 = Dense(channel//ratio, activation=\"relu\", use_bias=False)\n",
    "    l2 = Dense(channel, use_bias=False)\n",
    "    \n",
    "    x1 = GlobalAveragePooling2D()(x)\n",
    "    x1 = l1(x1)\n",
    "    x1 = l2(x1)\n",
    "    \n",
    "    x2 = GlobalMaxPooling2D()(x)\n",
    "    x2 = l1(x2)\n",
    "    x2 = l2(x2)\n",
    "    \n",
    "    feats = x1 + x2\n",
    "    feats = Activation(\"sigmoid\")(feats)\n",
    "    \n",
    "    feats = Multiply()([x, feats])\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_attention_module(x):\n",
    "    x1 = tf.reduce_mean(x, axis=-1)\n",
    "    x1 = tf.expand_dims(x1, axis=-1)\n",
    "    \n",
    "    x2 = tf.reduce_max(x, axis=-1)\n",
    "    x2 = tf.expand_dims(x2, axis=-1)\n",
    "    \n",
    "    feats = Concatenate()([x1, x2])\n",
    "    feats = Conv2D(1, kernel_size=7, padding=\"same\", activation=\"sigmoid\")(feats)\n",
    "    \n",
    "    feats = Multiply()([x, feats])\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam(x):\n",
    "    x = channel_attention_module(x)\n",
    "    x = spatial_attention_module(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = cbam(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skip, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    \"\"\" ResNet50 Encoder \"\"\"\n",
    "    resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "    \n",
    "    s1 = resnet50.get_layer(\"input_1\").output\n",
    "    s2 = resnet50.get_layer(\"conv1_relu\").output\n",
    "    s3 = resnet50.get_layer(\"conv2_block3_out\").output\n",
    "    s4 = resnet50.get_layer(\"conv3_block4_out\").output\n",
    "    \n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = resnet50.get_layer(\"conv4_block6_out\").output\n",
    "    \n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "    \n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "    \n",
    "    model = Model(inputs, outputs, name=\"UNET\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    train_x = sorted(glob(os.path.join(path, \"train\", \"images\", \"*\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"train\", \"masks\", \"*\")))\n",
    "    \n",
    "    valid_x = sorted(glob(os.path.join(path, \"valid\", \"images\", \"*\")))\n",
    "    valid_y = sorted(glob(os.path.join(path, \"valid\", \"masks\", \"*\")))\n",
    "    \n",
    "    return (train_x, train_y), (valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (width, height))\n",
    "    x = x/255.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (width, height))\n",
    "    x = x/255.0\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "    \n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
    "    x.set_shape([height, width, 3])\n",
    "    y.set_shape([height, width, 1])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset(x, y, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 536 - 536\n",
      "Valid: 67 - 67\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y), (valid_x, valid_y) = load_data(dataset_path)\n",
    "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
    "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (height, width, 3)\n",
    "model = build_unet(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNET\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 262, 262, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 128, 128, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 128, 128, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 128, 128, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 130, 130, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 64, 64, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 64, 64, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 64, 64, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 64, 64, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 32, 32, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 32, 32, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 32, 32, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 32, 32, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 16, 16, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 16, 16, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 16, 16, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 16, 16, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 16, 16, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 16, 16, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  2097664    ['conv4_block6_out[0][0]']       \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 512)  4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 512)  2048       ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 32, 512)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 512)  2359808     ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 512)         0           ['activation_1[0][0]']           \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " global_max_pooling2d (GlobalMa  (None, 512)         0           ['activation_1[0][0]']           \n",
      " xPooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           32768       ['global_average_pooling2d[0][0]'\n",
      "                                                                 , 'global_max_pooling2d[0][0]']  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          32768       ['dense[0][0]',                  \n",
      "                                                                  'dense[1][0]']                  \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 512)         0           ['dense_1[0][0]',                \n",
      " da)                                                              'dense_1[1][0]']                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 512)          0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 32, 32, 512)  0           ['activation_1[0][0]',           \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 32, 32)      0           ['multiply[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLambda  (None, 32, 32)      0           ['multiply[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 32, 32, 1)    0           ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (None, 32, 32, 1)    0           ['tf.math.reduce_max[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 32, 32, 2)    0           ['tf.expand_dims[0][0]',         \n",
      "                                                                  'tf.expand_dims_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 1)    99          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 32, 32, 512)  0           ['multiply[0][0]',               \n",
      "                                                                  'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  524544     ['multiply_1[0][0]']             \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 64, 256)  1179904     ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 256)         0           ['activation_4[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling2d_1 (Global  (None, 256)         0           ['activation_4[0][0]']           \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           8192        ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_max_pooling2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          8192        ['dense_2[0][0]',                \n",
      "                                                                  'dense_2[1][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 256)         0           ['dense_3[0][0]',                \n",
      " mbda)                                                            'dense_3[1][0]']                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 256)          0           ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 64, 64, 256)  0           ['activation_4[0][0]',           \n",
      "                                                                  'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_1 (TFOpLam  (None, 64, 64)      0           ['multiply_2[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_1 (TFOpLamb  (None, 64, 64)      0           ['multiply_2[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_2 (TFOpLambda)  (None, 64, 64, 1)    0           ['tf.math.reduce_mean_1[0][0]']  \n",
      "                                                                                                  \n",
      " tf.expand_dims_3 (TFOpLambda)  (None, 64, 64, 1)    0           ['tf.math.reduce_max_1[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 64, 64, 2)    0           ['tf.expand_dims_2[0][0]',       \n",
      "                                                                  'tf.expand_dims_3[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 1)    99          ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 64, 64, 256)  0           ['multiply_2[0][0]',             \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  131200     ['multiply_3[0][0]']             \n",
      " spose)                         8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 128, 128, 19  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                2)                                'conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 128, 128, 12  221312      ['concatenate_4[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 128, 128, 12  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_4[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 128, 128, 12  147584      ['activation_6[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 128, 128, 12  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_5[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 128)         0           ['activation_7[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling2d_2 (Global  (None, 128)         0           ['activation_7[0][0]']           \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 16)           2048        ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_max_pooling2d_2[0][0]'] \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          2048        ['dense_4[0][0]',                \n",
      "                                                                  'dense_4[1][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 128)         0           ['dense_5[0][0]',                \n",
      " mbda)                                                            'dense_5[1][0]']                \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 128)          0           ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 128, 128, 12  0           ['activation_7[0][0]',           \n",
      "                                8)                                'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  (None, 128, 128)    0           ['multiply_4[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_2 (TFOpLamb  (None, 128, 128)    0           ['multiply_4[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_4 (TFOpLambda)  (None, 128, 128, 1)  0           ['tf.math.reduce_mean_2[0][0]']  \n",
      "                                                                                                  \n",
      " tf.expand_dims_5 (TFOpLambda)  (None, 128, 128, 1)  0           ['tf.math.reduce_max_2[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 128, 128, 2)  0           ['tf.expand_dims_4[0][0]',       \n",
      "                                                                  'tf.expand_dims_5[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 128, 128, 1)  99          ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 128, 128, 12  0           ['multiply_4[0][0]',             \n",
      "                                8)                                'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  32832      ['multiply_5[0][0]']             \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 256, 256, 67  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                )                                 'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 256, 256, 64  38656       ['concatenate_6[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 256, 256, 64  256        ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 256, 256, 64  36928       ['activation_9[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 256, 256, 64  256        ['conv2d_10[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 64)          0           ['activation_10[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling2d_3 (Global  (None, 64)          0           ['activation_10[0][0]']          \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 8)            512         ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_max_pooling2d_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 64)           512         ['dense_6[0][0]',                \n",
      "                                                                  'dense_6[1][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 64)          0           ['dense_7[0][0]',                \n",
      " mbda)                                                            'dense_7[1][0]']                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 64)           0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 256, 256, 64  0           ['activation_10[0][0]',          \n",
      "                                )                                 'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_3 (TFOpLam  (None, 256, 256)    0           ['multiply_6[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_3 (TFOpLamb  (None, 256, 256)    0           ['multiply_6[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_6 (TFOpLambda)  (None, 256, 256, 1)  0           ['tf.math.reduce_mean_3[0][0]']  \n",
      "                                                                                                  \n",
      " tf.expand_dims_7 (TFOpLambda)  (None, 256, 256, 1)  0           ['tf.math.reduce_max_3[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 256, 256, 2)  0           ['tf.expand_dims_6[0][0]',       \n",
      "                                                                  'tf.expand_dims_7[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 256, 256, 1)  99          ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 256, 256, 64  0           ['multiply_6[0][0]',             \n",
      "                                )                                 'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 256, 256, 1)  65          ['multiply_7[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,763,981\n",
      "Trainable params: 20,729,549\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    dice = (2. * intersection + 1e-15) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + 1e-15)\n",
    "    return 1.0 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "model.compile(loss=dice_loss, optimizer=opt, metrics=[\"acc\"], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        ModelCheckpoint(model_file, verbose=1, save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10),\n",
    "        CSVLogger(log_file),\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6200 - acc: 0.7353\n",
      "Epoch 1: val_loss improved from inf to 0.79378, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 555s 8s/step - loss: 0.6200 - acc: 0.7353 - val_loss: 0.7938 - val_acc: 0.0837 - lr: 2.0000e-04\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.4245 - acc: 0.8338\n",
      "Epoch 2: val_loss improved from 0.79378 to 0.78749, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 555s 8s/step - loss: 0.4245 - acc: 0.8338 - val_loss: 0.7875 - val_acc: 0.0837 - lr: 2.0000e-04\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3254 - acc: 0.8551\n",
      "Epoch 3: val_loss did not improve from 0.78749\n",
      "67/67 [==============================] - 550s 8s/step - loss: 0.3254 - acc: 0.8551 - val_loss: 0.7937 - val_acc: 0.8136 - lr: 2.0000e-04\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2478 - acc: 0.8623 \n",
      "Epoch 4: val_loss did not improve from 0.78749\n",
      "67/67 [==============================] - 1504s 23s/step - loss: 0.2478 - acc: 0.8623 - val_loss: 0.8032 - val_acc: 0.8135 - lr: 2.0000e-04\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1941 - acc: 0.8656\n",
      "Epoch 5: val_loss did not improve from 0.78749\n",
      "67/67 [==============================] - 550s 8s/step - loss: 0.1941 - acc: 0.8656 - val_loss: 0.8118 - val_acc: 0.8127 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1600 - acc: 0.8683\n",
      "Epoch 6: val_loss did not improve from 0.78749\n",
      "67/67 [==============================] - 531s 8s/step - loss: 0.1600 - acc: 0.8683 - val_loss: 0.8519 - val_acc: 0.8107 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1378 - acc: 0.8697\n",
      "Epoch 7: val_loss did not improve from 0.78749\n",
      "67/67 [==============================] - 516s 8s/step - loss: 0.1378 - acc: 0.8697 - val_loss: 0.8767 - val_acc: 0.8109 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1251 - acc: 0.8704\n",
      "Epoch 8: val_loss did not improve from 0.78749\n",
      "67/67 [==============================] - 514s 8s/step - loss: 0.1251 - acc: 0.8704 - val_loss: 0.8356 - val_acc: 0.8123 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1184 - acc: 0.8703\n",
      "Epoch 9: val_loss improved from 0.78749 to 0.70309, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 515s 8s/step - loss: 0.1184 - acc: 0.8703 - val_loss: 0.7031 - val_acc: 0.8132 - lr: 2.0000e-04\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1066 - acc: 0.8713\n",
      "Epoch 10: val_loss improved from 0.70309 to 0.53650, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 516s 8s/step - loss: 0.1066 - acc: 0.8713 - val_loss: 0.5365 - val_acc: 0.8151 - lr: 2.0000e-04\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0966 - acc: 0.8723\n",
      "Epoch 11: val_loss did not improve from 0.53650\n",
      "67/67 [==============================] - 523s 8s/step - loss: 0.0966 - acc: 0.8723 - val_loss: 0.5929 - val_acc: 0.8157 - lr: 2.0000e-04\n",
      "Epoch 12/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0919 - acc: 0.8726\n",
      "Epoch 12: val_loss improved from 0.53650 to 0.51283, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 523s 8s/step - loss: 0.0919 - acc: 0.8726 - val_loss: 0.5128 - val_acc: 0.7771 - lr: 2.0000e-04\n",
      "Epoch 13/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0868 - acc: 0.8730\n",
      "Epoch 13: val_loss improved from 0.51283 to 0.45047, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 523s 8s/step - loss: 0.0868 - acc: 0.8730 - val_loss: 0.4505 - val_acc: 0.8103 - lr: 2.0000e-04\n",
      "Epoch 14/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0854 - acc: 0.8730\n",
      "Epoch 14: val_loss improved from 0.45047 to 0.32045, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 515s 8s/step - loss: 0.0854 - acc: 0.8730 - val_loss: 0.3205 - val_acc: 0.8336 - lr: 2.0000e-04\n",
      "Epoch 15/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0843 - acc: 0.8730\n",
      "Epoch 15: val_loss improved from 0.32045 to 0.17949, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 518s 8s/step - loss: 0.0843 - acc: 0.8730 - val_loss: 0.1795 - val_acc: 0.8689 - lr: 2.0000e-04\n",
      "Epoch 16/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0950 - acc: 0.8709\n",
      "Epoch 16: val_loss did not improve from 0.17949\n",
      "67/67 [==============================] - 514s 8s/step - loss: 0.0950 - acc: 0.8709 - val_loss: 0.2333 - val_acc: 0.8517 - lr: 2.0000e-04\n",
      "Epoch 17/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0990 - acc: 0.8700\n",
      "Epoch 17: val_loss improved from 0.17949 to 0.14141, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 515s 8s/step - loss: 0.0990 - acc: 0.8700 - val_loss: 0.1414 - val_acc: 0.8773 - lr: 2.0000e-04\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0830 - acc: 0.8725\n",
      "Epoch 18: val_loss improved from 0.14141 to 0.12599, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 516s 8s/step - loss: 0.0830 - acc: 0.8725 - val_loss: 0.1260 - val_acc: 0.8788 - lr: 2.0000e-04\n",
      "Epoch 19/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0771 - acc: 0.8733\n",
      "Epoch 19: val_loss improved from 0.12599 to 0.10276, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 517s 8s/step - loss: 0.0771 - acc: 0.8733 - val_loss: 0.1028 - val_acc: 0.8824 - lr: 2.0000e-04\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0728 - acc: 0.8739\n",
      "Epoch 20: val_loss improved from 0.10276 to 0.09837, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 518s 8s/step - loss: 0.0728 - acc: 0.8739 - val_loss: 0.0984 - val_acc: 0.8830 - lr: 2.0000e-04\n",
      "Epoch 21/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0697 - acc: 0.8743\n",
      "Epoch 21: val_loss improved from 0.09837 to 0.09326, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 517s 8s/step - loss: 0.0697 - acc: 0.8743 - val_loss: 0.0933 - val_acc: 0.8838 - lr: 2.0000e-04\n",
      "Epoch 22/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0690 - acc: 0.8744\n",
      "Epoch 22: val_loss improved from 0.09326 to 0.09257, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 516s 8s/step - loss: 0.0690 - acc: 0.8744 - val_loss: 0.0926 - val_acc: 0.8837 - lr: 2.0000e-04\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0708 - acc: 0.8741\n",
      "Epoch 23: val_loss did not improve from 0.09257\n",
      "67/67 [==============================] - 517s 8s/step - loss: 0.0708 - acc: 0.8741 - val_loss: 0.0934 - val_acc: 0.8835 - lr: 2.0000e-04\n",
      "Epoch 24/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0712 - acc: 0.8738\n",
      "Epoch 24: val_loss did not improve from 0.09257\n",
      "67/67 [==============================] - 526s 8s/step - loss: 0.0712 - acc: 0.8738 - val_loss: 0.0954 - val_acc: 0.8833 - lr: 2.0000e-04\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0664 - acc: 0.8746\n",
      "Epoch 25: val_loss improved from 0.09257 to 0.09092, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 517s 8s/step - loss: 0.0664 - acc: 0.8746 - val_loss: 0.0909 - val_acc: 0.8839 - lr: 2.0000e-04\n",
      "Epoch 26/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0624 - acc: 0.8753\n",
      "Epoch 26: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 515s 8s/step - loss: 0.0624 - acc: 0.8753 - val_loss: 0.0933 - val_acc: 0.8833 - lr: 2.0000e-04\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0615 - acc: 0.8754\n",
      "Epoch 27: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 518s 8s/step - loss: 0.0615 - acc: 0.8754 - val_loss: 0.0915 - val_acc: 0.8837 - lr: 2.0000e-04\n",
      "Epoch 28/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0609 - acc: 0.8754\n",
      "Epoch 28: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 516s 8s/step - loss: 0.0609 - acc: 0.8754 - val_loss: 0.0913 - val_acc: 0.8837 - lr: 2.0000e-04\n",
      "Epoch 29/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0596 - acc: 0.8756\n",
      "Epoch 29: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 517s 8s/step - loss: 0.0596 - acc: 0.8756 - val_loss: 0.1005 - val_acc: 0.8819 - lr: 2.0000e-04\n",
      "Epoch 30/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0589 - acc: 0.8757\n",
      "Epoch 30: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 520s 8s/step - loss: 0.0589 - acc: 0.8757 - val_loss: 0.0933 - val_acc: 0.8834 - lr: 2.0000e-04\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0572 - acc: 0.8759\n",
      "Epoch 31: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 517s 8s/step - loss: 0.0572 - acc: 0.8759 - val_loss: 0.1005 - val_acc: 0.8821 - lr: 2.0000e-04\n",
      "Epoch 32/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0560 - acc: 0.8761\n",
      "Epoch 32: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 529s 8s/step - loss: 0.0560 - acc: 0.8761 - val_loss: 0.0935 - val_acc: 0.8833 - lr: 2.0000e-04\n",
      "Epoch 33/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0566 - acc: 0.8760\n",
      "Epoch 33: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 515s 8s/step - loss: 0.0566 - acc: 0.8760 - val_loss: 0.0919 - val_acc: 0.8836 - lr: 2.0000e-04\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0552 - acc: 0.8762\n",
      "Epoch 34: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 520s 8s/step - loss: 0.0552 - acc: 0.8762 - val_loss: 0.0996 - val_acc: 0.8821 - lr: 2.0000e-04\n",
      "Epoch 35/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0553 - acc: 0.8762\n",
      "Epoch 35: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 518s 8s/step - loss: 0.0553 - acc: 0.8762 - val_loss: 0.0945 - val_acc: 0.8831 - lr: 2.0000e-04\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0522 - acc: 0.8766\n",
      "Epoch 36: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 513s 8s/step - loss: 0.0522 - acc: 0.8766 - val_loss: 0.0911 - val_acc: 0.8839 - lr: 2.0000e-05\n",
      "Epoch 37/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0496 - acc: 0.8770\n",
      "Epoch 37: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 515s 8s/step - loss: 0.0496 - acc: 0.8770 - val_loss: 0.0911 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 38/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0482 - acc: 0.8772\n",
      "Epoch 38: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 515s 8s/step - loss: 0.0482 - acc: 0.8772 - val_loss: 0.0910 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 39/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0472 - acc: 0.8774\n",
      "Epoch 39: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 523s 8s/step - loss: 0.0472 - acc: 0.8774 - val_loss: 0.0910 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 40/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0464 - acc: 0.8775\n",
      "Epoch 40: val_loss did not improve from 0.09092\n",
      "67/67 [==============================] - 520s 8s/step - loss: 0.0464 - acc: 0.8775 - val_loss: 0.0909 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 41/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0457 - acc: 0.8776\n",
      "Epoch 41: val_loss improved from 0.09092 to 0.09087, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 520s 8s/step - loss: 0.0457 - acc: 0.8776 - val_loss: 0.0909 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 42/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0451 - acc: 0.8777\n",
      "Epoch 42: val_loss improved from 0.09087 to 0.09083, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 519s 8s/step - loss: 0.0451 - acc: 0.8777 - val_loss: 0.0908 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 43/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0445 - acc: 0.8778\n",
      "Epoch 43: val_loss improved from 0.09083 to 0.09081, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 521s 8s/step - loss: 0.0445 - acc: 0.8778 - val_loss: 0.0908 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 44/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0440 - acc: 0.8779\n",
      "Epoch 44: val_loss improved from 0.09081 to 0.09080, saving model to files\\unet.h5\n",
      "67/67 [==============================] - 517s 8s/step - loss: 0.0440 - acc: 0.8779 - val_loss: 0.0908 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 45/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0435 - acc: 0.8780\n",
      "Epoch 45: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 518s 8s/step - loss: 0.0435 - acc: 0.8780 - val_loss: 0.0908 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0430 - acc: 0.8781\n",
      "Epoch 46: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 514s 8s/step - loss: 0.0430 - acc: 0.8781 - val_loss: 0.0908 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0425 - acc: 0.8781\n",
      "Epoch 47: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 517s 8s/step - loss: 0.0425 - acc: 0.8781 - val_loss: 0.0909 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 48/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0421 - acc: 0.8782\n",
      "Epoch 48: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 514s 8s/step - loss: 0.0421 - acc: 0.8782 - val_loss: 0.0909 - val_acc: 0.8837 - lr: 2.0000e-05\n",
      "Epoch 49/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0417 - acc: 0.8783\n",
      "Epoch 49: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 515s 8s/step - loss: 0.0417 - acc: 0.8783 - val_loss: 0.0910 - val_acc: 0.8837 - lr: 2.0000e-05\n",
      "Epoch 50/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0413 - acc: 0.8783\n",
      "Epoch 50: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 523s 8s/step - loss: 0.0413 - acc: 0.8783 - val_loss: 0.0911 - val_acc: 0.8837 - lr: 2.0000e-05\n",
      "Epoch 51/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0409 - acc: 0.8784\n",
      "Epoch 51: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 517s 8s/step - loss: 0.0409 - acc: 0.8784 - val_loss: 0.0911 - val_acc: 0.8837 - lr: 2.0000e-05\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0406 - acc: 0.8784\n",
      "Epoch 52: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 521s 8s/step - loss: 0.0406 - acc: 0.8784 - val_loss: 0.0912 - val_acc: 0.8836 - lr: 2.0000e-05\n",
      "Epoch 53/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0403 - acc: 0.8785\n",
      "Epoch 53: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 519s 8s/step - loss: 0.0403 - acc: 0.8785 - val_loss: 0.0910 - val_acc: 0.8837 - lr: 2.0000e-05\n",
      "Epoch 54/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0401 - acc: 0.8785\n",
      "Epoch 54: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 522s 8s/step - loss: 0.0401 - acc: 0.8785 - val_loss: 0.0912 - val_acc: 0.8836 - lr: 2.0000e-06\n",
      "Epoch 55/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0399 - acc: 0.8785\n",
      "Epoch 55: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 517s 8s/step - loss: 0.0399 - acc: 0.8785 - val_loss: 0.0912 - val_acc: 0.8836 - lr: 2.0000e-06\n",
      "Epoch 56/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0398 - acc: 0.8785\n",
      "Epoch 56: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 518s 8s/step - loss: 0.0398 - acc: 0.8785 - val_loss: 0.0912 - val_acc: 0.8836 - lr: 2.0000e-06\n",
      "Epoch 57/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0397 - acc: 0.8785\n",
      "Epoch 57: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 516s 8s/step - loss: 0.0397 - acc: 0.8785 - val_loss: 0.0912 - val_acc: 0.8836 - lr: 2.0000e-06\n",
      "Epoch 58/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0396 - acc: 0.8786\n",
      "Epoch 58: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 523s 8s/step - loss: 0.0396 - acc: 0.8786 - val_loss: 0.0912 - val_acc: 0.8836 - lr: 2.0000e-06\n",
      "Epoch 59/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0396 - acc: 0.8786\n",
      "Epoch 59: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 518s 8s/step - loss: 0.0396 - acc: 0.8786 - val_loss: 0.0912 - val_acc: 0.8836 - lr: 2.0000e-06\n",
      "Epoch 60/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0395 - acc: 0.8786\n",
      "Epoch 60: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 520s 8s/step - loss: 0.0395 - acc: 0.8786 - val_loss: 0.0912 - val_acc: 0.8836 - lr: 2.0000e-06\n",
      "Epoch 61/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0395 - acc: 0.8786\n",
      "Epoch 61: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 520s 8s/step - loss: 0.0395 - acc: 0.8786 - val_loss: 0.0912 - val_acc: 0.8836 - lr: 2.0000e-06\n",
      "Epoch 62/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0394 - acc: 0.8786\n",
      "Epoch 62: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 517s 8s/step - loss: 0.0394 - acc: 0.8786 - val_loss: 0.0912 - val_acc: 0.8836 - lr: 2.0000e-06\n",
      "Epoch 63/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0393 - acc: 0.8786\n",
      "Epoch 63: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 517s 8s/step - loss: 0.0393 - acc: 0.8786 - val_loss: 0.0912 - val_acc: 0.8836 - lr: 2.0000e-06\n",
      "Epoch 64/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0393 - acc: 0.8786\n",
      "Epoch 64: val_loss did not improve from 0.09080\n",
      "67/67 [==============================] - 520s 8s/step - loss: 0.0393 - acc: 0.8786 - val_loss: 0.0912 - val_acc: 0.8836 - lr: 2.0000e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13505cd0310>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=valid_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    batch_size=32\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
