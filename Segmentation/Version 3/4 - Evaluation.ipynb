{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span  style=\"font-size: 20px; line-height: 30px;\">\n",
    "Calculate metrics:\n",
    "    \n",
    "<ol>\n",
    "    <li> F1 </li>\n",
    "    <li> Mean IoU </li>\n",
    "    <li> Recall </li>\n",
    "    <li> Precision </li>\n",
    "    <li> Accuracy </li>\n",
    "</ol>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 256\n",
    "width = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load predict mask and ground truth Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask = sorted(glob(os.path.join(\"prediction\", \"*\")))\n",
    "true_mask = sorted(glob(os.path.join(\"dataset\", \"test\", \"masks\", \"*\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 30/67 [00:01<00:01, 24.88it/s]C:\\Users\\sheri\\.conda\\envs\\midterm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      " 49%|████▉     | 33/67 [00:01<00:01, 24.92it/s]C:\\Users\\sheri\\.conda\\envs\\midterm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sheri\\.conda\\envs\\midterm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      " 58%|█████▊    | 39/67 [00:01<00:01, 24.67it/s]C:\\Users\\sheri\\.conda\\envs\\midterm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      " 63%|██████▎   | 42/67 [00:01<00:01, 24.26it/s]C:\\Users\\sheri\\.conda\\envs\\midterm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      " 85%|████████▌ | 57/67 [00:02<00:00, 24.82it/s]C:\\Users\\sheri\\.conda\\envs\\midterm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "100%|██████████| 67/67 [00:02<00:00, 24.96it/s]\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "\n",
    "for pred_y, true_y in tqdm(zip(pred_mask, true_mask), total=len(pred_mask)):\n",
    "    name = pred_y.split(\"\\\\\")[-1]\n",
    "    \n",
    "    pred_y = cv2.imread(pred_y, cv2.IMREAD_GRAYSCALE)\n",
    "    pred_y = pred_y/255.0\n",
    "    pred_y = pred_y > 0.5\n",
    "    pred_y = pred_y.astype(np.int32)\n",
    "    pred_y = pred_y.flatten()\n",
    "    \n",
    "    true_y = cv2.imread(true_y, cv2.IMREAD_GRAYSCALE)\n",
    "    true_y = true_y/255.0\n",
    "    true_y = true_y > 0.5\n",
    "    true_y = true_y.astype(np.int32)\n",
    "    true_y = true_y.flatten()\n",
    "    \n",
    "    acc_value = accuracy_score(pred_y, true_y)\n",
    "    f1_value = f1_score(pred_y, true_y, labels=[0, 1], average=\"binary\")\n",
    "    jac_value = jaccard_score(pred_y, true_y, labels=[0, 1], average=\"binary\")\n",
    "    recall_value = recall_score(pred_y, true_y, labels=[0, 1], average=\"binary\")\n",
    "    precision_value = precision_score(pred_y, true_y, labels=[0, 1], average=\"binary\")\n",
    "    score.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.12668\n",
      "F1: 0.20737\n",
      "Jaccard: 0.12661\n",
      "Recall: 0.12662\n",
      "Precision: 0.91036\n"
     ]
    }
   ],
   "source": [
    "score = [s[1:]for s in score]\n",
    "score = np.mean(score, axis=0)\n",
    "print(f\"Accuracy: {score[0]:0.5f}\")\n",
    "print(f\"F1: {score[1]:0.5f}\")\n",
    "print(f\"Jaccard: {score[2]:0.5f}\")\n",
    "print(f\"Recall: {score[3]:0.5f}\")\n",
    "print(f\"Precision: {score[4]:0.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
